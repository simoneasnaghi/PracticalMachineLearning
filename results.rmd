---
title: "Practical Machine Learning Course Project"
author: "Simone Asnaghi"
date: "Saturday, November 21, 2015"
output: html_document
---

# Practical Machine Learning Course Project

## Simone Asnaghi
*Saturday, November 21, 2015*

This is the Final Project for the "Practical Machine Learning" course from Johns Hopkins University.
Following Background and Data are taken from project assignment page.

## Background

Using devices such as Jawbone Up, Nike FuelBand, and Fitbit it is now possible to collect a large amount of data about personal activity relatively inexpensively. These type of devices are part of the quantified self movement - a group of enthusiasts who take measurements about themselves regularly to improve their health, to find patterns in their behavior, or because they are tech geeks. One thing that people regularly do is quantify how much of a particular activity they do, but they rarely quantify how well they do it. In this project, your goal will be to use data from accelerometers on the belt, forearm, arm, and dumbell of 6 participants. They were asked to perform barbell lifts correctly and incorrectly in 5 different ways. More information is available from the website here: [http://groupware.les.inf.puc-rio.br/har] (see the section on the Weight Lifting Exercise Dataset).

## Data

The training data for this project are available here: [https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv]

The test data are available here: [https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv]

The data for this project come from this source: [http://groupware.les.inf.puc-rio.br/har]. If you use the document you create for this class for any purpose please cite them as they have been very generous in allowing their data to be used for this kind of assignment.

## Work

#### Load data and library

Needed libraries and original data are loaded. Missing values, "#DIV/0!", "" and "NA" are changed to NA.  Converting 'classe' into factor.

```r
library(caret)

trainingOrg <- read.csv(file="pml-training.csv", na.strings=c('NA','','#DIV/0!'))
testingOrg <- read.csv(file="pml-testing.csv", na.strings=c('NA','','#DIV/0!'))
trainingOrg$classe <- as.factor(trainingOrg$classe)  
```

#### Examine data

```r
str(trainingOrg)
'data.frame':   19622 obs. of  160 variables:
 $ X                       : int  1 2 3 4 5 6 7 8 9 10 ...
 $ user_name               : Factor w/ 6 levels "adelmo","carlitos",..: 2 2 2 2 2 2 2 2 2 2 ...
 $ raw_timestamp_part_1    : int  1323084231 1323084231 1323084231 1323084232 1323084232 1323084232 1323084232 1323084232 1323084232 1323084232 ...
 $ raw_timestamp_part_2    : int  788290 808298 820366 120339 196328 304277 368296 440390 484323 484434 ...
 $ cvtd_timestamp          : Factor w/ 20 levels "02/12/2011 13:32",..: 9 9 9 9 9 9 9 9 9 9 ...
 $ new_window              : Factor w/ 2 levels "no","yes": 1 1 1 1 1 1 1 1 1 1 ...
 $ num_window              : int  11 11 11 12 12 12 12 12 12 12 ...
 $ roll_belt               : num  1.41 1.41 1.42 1.48 1.48 1.45 1.42 1.42 1.43 1.45 ...
 $ pitch_belt              : num  8.07 8.07 8.07 8.05 8.07 8.06 8.09 8.13 8.16 8.17 ...
 $ yaw_belt                : num  -94.4 -94.4 -94.4 -94.4 -94.4 -94.4 -94.4 -94.4 -94.4 -94.4 ...
 $ total_accel_belt        : int  3 3 3 3 3 3 3 3 3 3 ...
 $ kurtosis_roll_belt      : num  NA NA NA NA NA NA NA NA NA NA ...
 $ kurtosis_picth_belt     : num  NA NA NA NA NA NA NA NA NA NA ...
 $ kurtosis_yaw_belt       : logi  NA NA NA NA NA NA ...
 $ skewness_roll_belt      : num  NA NA NA NA NA NA NA NA NA NA ...
 $ skewness_roll_belt.1    : num  NA NA NA NA NA NA NA NA NA NA ...
 $ skewness_yaw_belt       : logi  NA NA NA NA NA NA ...
 $ max_roll_belt           : num  NA NA NA NA NA NA NA NA NA NA ...
 $ max_picth_belt          : int  NA NA NA NA NA NA NA NA NA NA ...
 $ max_yaw_belt            : num  NA NA NA NA NA NA NA NA NA NA ...
 $ min_roll_belt           : num  NA NA NA NA NA NA NA NA NA NA ...
 $ min_pitch_belt          : int  NA NA NA NA NA NA NA NA NA NA ...
 $ min_yaw_belt            : num  NA NA NA NA NA NA NA NA NA NA ...
 $ amplitude_roll_belt     : num  NA NA NA NA NA NA NA NA NA NA ...
 $ amplitude_pitch_belt    : int  NA NA NA NA NA NA NA NA NA NA ...
 $ amplitude_yaw_belt      : num  NA NA NA NA NA NA NA NA NA NA ...
 $ var_total_accel_belt    : num  NA NA NA NA NA NA NA NA NA NA ...
 $ avg_roll_belt           : num  NA NA NA NA NA NA NA NA NA NA ...
 $ stddev_roll_belt        : num  NA NA NA NA NA NA NA NA NA NA ...
 $ var_roll_belt           : num  NA NA NA NA NA NA NA NA NA NA ...
 $ avg_pitch_belt          : num  NA NA NA NA NA NA NA NA NA NA ...
 $ stddev_pitch_belt       : num  NA NA NA NA NA NA NA NA NA NA ...
 $ var_pitch_belt          : num  NA NA NA NA NA NA NA NA NA NA ...
 $ avg_yaw_belt            : num  NA NA NA NA NA NA NA NA NA NA ...
 $ stddev_yaw_belt         : num  NA NA NA NA NA NA NA NA NA NA ...
 $ var_yaw_belt            : num  NA NA NA NA NA NA NA NA NA NA ...
 $ gyros_belt_x            : num  0 0.02 0 0.02 0.02 0.02 0.02 0.02 0.02 0.03 ...
 $ gyros_belt_y            : num  0 0 0 0 0.02 0 0 0 0 0 ...
 $ gyros_belt_z            : num  -0.02 -0.02 -0.02 -0.03 -0.02 -0.02 -0.02 -0.02 -0.02 0 ...
 $ accel_belt_x            : int  -21 -22 -20 -22 -21 -21 -22 -22 -20 -21 ...
 $ accel_belt_y            : int  4 4 5 3 2 4 3 4 2 4 ...
 $ accel_belt_z            : int  22 22 23 21 24 21 21 21 24 22 ...
 $ magnet_belt_x           : int  -3 -7 -2 -6 -6 0 -4 -2 1 -3 ...
 $ magnet_belt_y           : int  599 608 600 604 600 603 599 603 602 609 ...
 $ magnet_belt_z           : int  -313 -311 -305 -310 -302 -312 -311 -313 -312 -308 ...
 $ roll_arm                : num  -128 -128 -128 -128 -128 -128 -128 -128 -128 -128 ...
 $ pitch_arm               : num  22.5 22.5 22.5 22.1 22.1 22 21.9 21.8 21.7 21.6 ...
 $ yaw_arm                 : num  -161 -161 -161 -161 -161 -161 -161 -161 -161 -161 ...
 $ total_accel_arm         : int  34 34 34 34 34 34 34 34 34 34 ...
 $ var_accel_arm           : num  NA NA NA NA NA NA NA NA NA NA ...
 $ avg_roll_arm            : num  NA NA NA NA NA NA NA NA NA NA ...
 $ stddev_roll_arm         : num  NA NA NA NA NA NA NA NA NA NA ...
 $ var_roll_arm            : num  NA NA NA NA NA NA NA NA NA NA ...
 $ avg_pitch_arm           : num  NA NA NA NA NA NA NA NA NA NA ...
 $ stddev_pitch_arm        : num  NA NA NA NA NA NA NA NA NA NA ...
 $ var_pitch_arm           : num  NA NA NA NA NA NA NA NA NA NA ...
 $ avg_yaw_arm             : num  NA NA NA NA NA NA NA NA NA NA ...
 $ stddev_yaw_arm          : num  NA NA NA NA NA NA NA NA NA NA ...
 $ var_yaw_arm             : num  NA NA NA NA NA NA NA NA NA NA ...
 $ gyros_arm_x             : num  0 0.02 0.02 0.02 0 0.02 0 0.02 0.02 0.02 ...
 $ gyros_arm_y             : num  0 -0.02 -0.02 -0.03 -0.03 -0.03 -0.03 -0.02 -0.03 -0.03 ...
 $ gyros_arm_z             : num  -0.02 -0.02 -0.02 0.02 0 0 0 0 -0.02 -0.02 ...
 $ accel_arm_x             : int  -288 -290 -289 -289 -289 -289 -289 -289 -288 -288 ...
 $ accel_arm_y             : int  109 110 110 111 111 111 111 111 109 110 ...
 $ accel_arm_z             : int  -123 -125 -126 -123 -123 -122 -125 -124 -122 -124 ...
 $ magnet_arm_x            : int  -368 -369 -368 -372 -374 -369 -373 -372 -369 -376 ...
 $ magnet_arm_y            : int  337 337 344 344 337 342 336 338 341 334 ...
 $ magnet_arm_z            : int  516 513 513 512 506 513 509 510 518 516 ...
 $ kurtosis_roll_arm       : num  NA NA NA NA NA NA NA NA NA NA ...
 $ kurtosis_picth_arm      : num  NA NA NA NA NA NA NA NA NA NA ...
 $ kurtosis_yaw_arm        : num  NA NA NA NA NA NA NA NA NA NA ...
 $ skewness_roll_arm       : num  NA NA NA NA NA NA NA NA NA NA ...
 $ skewness_pitch_arm      : num  NA NA NA NA NA NA NA NA NA NA ...
 $ skewness_yaw_arm        : num  NA NA NA NA NA NA NA NA NA NA ...
 $ max_roll_arm            : num  NA NA NA NA NA NA NA NA NA NA ...
 $ max_picth_arm           : num  NA NA NA NA NA NA NA NA NA NA ...
 $ max_yaw_arm             : int  NA NA NA NA NA NA NA NA NA NA ...
 $ min_roll_arm            : num  NA NA NA NA NA NA NA NA NA NA ...
 $ min_pitch_arm           : num  NA NA NA NA NA NA NA NA NA NA ...
 $ min_yaw_arm             : int  NA NA NA NA NA NA NA NA NA NA ...
 $ amplitude_roll_arm      : num  NA NA NA NA NA NA NA NA NA NA ...
 $ amplitude_pitch_arm     : num  NA NA NA NA NA NA NA NA NA NA ...
 $ amplitude_yaw_arm       : int  NA NA NA NA NA NA NA NA NA NA ...
 $ roll_dumbbell           : num  13.1 13.1 12.9 13.4 13.4 ...
 $ pitch_dumbbell          : num  -70.5 -70.6 -70.3 -70.4 -70.4 ...
 $ yaw_dumbbell            : num  -84.9 -84.7 -85.1 -84.9 -84.9 ...
 $ kurtosis_roll_dumbbell  : num  NA NA NA NA NA NA NA NA NA NA ...
 $ kurtosis_picth_dumbbell : num  NA NA NA NA NA NA NA NA NA NA ...
 $ kurtosis_yaw_dumbbell   : logi  NA NA NA NA NA NA ...
 $ skewness_roll_dumbbell  : num  NA NA NA NA NA NA NA NA NA NA ...
 $ skewness_pitch_dumbbell : num  NA NA NA NA NA NA NA NA NA NA ...
 $ skewness_yaw_dumbbell   : logi  NA NA NA NA NA NA ...
 $ max_roll_dumbbell       : num  NA NA NA NA NA NA NA NA NA NA ...
 $ max_picth_dumbbell      : num  NA NA NA NA NA NA NA NA NA NA ...
 $ max_yaw_dumbbell        : num  NA NA NA NA NA NA NA NA NA NA ...
 $ min_roll_dumbbell       : num  NA NA NA NA NA NA NA NA NA NA ...
 $ min_pitch_dumbbell      : num  NA NA NA NA NA NA NA NA NA NA ...
 $ min_yaw_dumbbell        : num  NA NA NA NA NA NA NA NA NA NA ...
 $ amplitude_roll_dumbbell : num  NA NA NA NA NA NA NA NA NA NA ...
  [list output truncated]
```

#### Data cleaning
Data is cleaned removing NA, near zero variance predictor and columns not useful for classification (like x, user name, time stamps and windows).

```r
NAindex <- apply(trainingOrg,2,function(x) {sum(is.na(x))}) 
trainingNNA <- trainingOrg[,which(NAindex == 0)]
NAindex <- apply(testingOrg,2,function(x) {sum(is.na(x))}) 
testingNNA <- testingOrg[,which(NAindex == 0)]
 
nzv <- nearZeroVar(trainingNNA,saveMetrics=TRUE)
trainingNZV <- trainingNNA[,nzv$nzv==FALSE]
nzv <- nearZeroVar(testingNNA,saveMetrics=TRUE)
testingNZV <- testingNNA[,nzv$nzv==FALSE]
 
dim(trainingNZV)
[1] 19622    59
dim(testingNZV)
[1] 20 59
 
dimTrain <- dim(trainingNZV)
dimTest <- dim(testingNZV)

trainingFIN <- trainingNZV[,7:dimTrain[2]]
testingFIN <- testingNZV[,7:dimTest[2]]
``` 

#### Partitioning training set for cross validation
The training set is splitted in two parts, train set (60%) and crossValidation set (40%)

```r
set.seed(12345)
 
inTrain = createDataPartition(trainingFIN$classe, p = 0.6, list=FALSE)
train = trainingFIN[inTrain,]
crossValidation = trainingFIN[-inTrain,]
``` 

#### Model creation
Random forest is choosed due to its highly accuracy rate. Cross validation is used as train control method.

```r
model <- train(classe ~ ., data=train, method="rf", trControl=trainControl(method='cv'))

model
Random Forest 

11776 samples
   52 predictor
    5 classes: 'A', 'B', 'C', 'D', 'E' 

No pre-processing
Resampling: Cross-Validated (10 fold) 
Summary of sample sizes: 10598, 10597, 10598, 10598, 10601, 10598, ... 
Resampling results across tuning parameters:

  mtry  Accuracy   Kappa      Accuracy SD  Kappa SD   
   2    0.9893007  0.9864643  0.003154799  0.003991127
  27    0.9892135  0.9863554  0.003762755  0.004759175
  52    0.9859865  0.9822711  0.003574370  0.004519865

Accuracy was used to select the optimal model using  the largest value.
The final value used for the model was mtry = 2. 
```

#### Accuracy

Accuracy of training (in sample accuracy) and cross validation (out of sample accuracy) sets is calculated.
The latter is 0.9929.

```r
trainingPred <- predict(model, train)
confusionMatrix(trainingPred, train$classe)

Confusion Matrix and Statistics

          Reference
Prediction    A    B    C    D    E
         A 3348    0    0    0    0
         B    0 2279    0    0    0
         C    0    0 2054    0    0
         D    0    0    0 1930    0
         E    0    0    0    0 2165

Overall Statistics
                                     
               Accuracy : 1          
                 95% CI : (0.9997, 1)
    No Information Rate : 0.2843     
    P-Value [Acc > NIR] : < 2.2e-16  
                                     
                  Kappa : 1          
 Mcnemar's Test P-Value : NA         

Statistics by Class:

                     Class: A Class: B Class: C Class: D Class: E
Sensitivity            1.0000   1.0000   1.0000   1.0000   1.0000
Specificity            1.0000   1.0000   1.0000   1.0000   1.0000
Pos Pred Value         1.0000   1.0000   1.0000   1.0000   1.0000
Neg Pred Value         1.0000   1.0000   1.0000   1.0000   1.0000
Prevalence             0.2843   0.1935   0.1744   0.1639   0.1838
Detection Rate         0.2843   0.1935   0.1744   0.1639   0.1838
Detection Prevalence   0.2843   0.1935   0.1744   0.1639   0.1838
Balanced Accuracy      1.0000   1.0000   1.0000   1.0000   1.0000
 
crossPred <- predict(model, crossValidation)
confusionMatrix(crossPred, crossValidation$classe)

Confusion Matrix and Statistics

          Reference
Prediction    A    B    C    D    E
         A 2229   10    0    0    0
         B    3 1503    6    0    0
         C    0    5 1361   24    2
         D    0    0    1 1260    3
         E    0    0    0    2 1437

Overall Statistics
                                          
               Accuracy : 0.9929          
                 95% CI : (0.9907, 0.9946)
    No Information Rate : 0.2845          
    P-Value [Acc > NIR] : < 2.2e-16       
                                          
                  Kappa : 0.991           
 Mcnemar's Test P-Value : NA              

Statistics by Class:

                     Class: A Class: B Class: C Class: D Class: E
Sensitivity            0.9987   0.9901   0.9949   0.9798   0.9965
Specificity            0.9982   0.9986   0.9952   0.9994   0.9997
Pos Pred Value         0.9955   0.9940   0.9777   0.9968   0.9986
Neg Pred Value         0.9995   0.9976   0.9989   0.9960   0.9992
Prevalence             0.2845   0.1935   0.1744   0.1639   0.1838
Detection Rate         0.2841   0.1916   0.1735   0.1606   0.1832
Detection Prevalence   0.2854   0.1927   0.1774   0.1611   0.1834
Balanced Accuracy      0.9984   0.9943   0.9950   0.9896   0.9981
``` 


### Prediction on test data

Now the model is used to perform prediction on (real) testing data

```r
testingPred <- predict(model, testingNZV)
testingPred
 [1] B A B A A E D B A A B C B A E E A B B B
Levels: A B C D E
``` 